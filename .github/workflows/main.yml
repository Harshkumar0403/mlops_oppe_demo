name: MLOps Pipeline for Fraud Detection

on:
  push:
    branches: [ main ]

permissions:
  contents: read
  id-token: write

env:
  PROJECT_ID: phonic-axle-473506-u8
  REGION: asia-south1
  ARTIFACT_REPO: fraud-api-repo
  IMAGE_NAME: fraud-api
  GKE_CLUSTER: fraud-api-cluster
  GKE_ZONE: asia-south1-a
  GCS_BUCKET: data_mlops_oppe2prep

jobs:
  build-validate-deploy:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      # ------------------------------------------
      # CHECKOUT + PYTHON ENV
      # ------------------------------------------
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m venv .venv
          source .venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt

      # ------------------------------------------
      # GCP AUTH + DVC PULL (RAW JSON KEY)
      # ------------------------------------------
      - name: Set up GCP credentials and authenticate
        env:
          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
        run: |
          set -e
          # Write JSON straight from secret
          echo "$GCP_SA_KEY" > gcp-key.json
          echo "âœ“ Wrote service account key to gcp-key.json"
          python3 -m json.tool gcp-key.json > /dev/null && echo "âœ“ Valid JSON"
          echo "Installing Google Cloud CLI..."
          sudo apt-get update && sudo apt-get install -y google-cloud-cli
          echo "Authenticating with GCP..."
          gcloud auth activate-service-account --key-file=gcp-key.json
          gcloud config set project phonic-axle-473506-u8
          # ðŸ‘‰ Make credentials visible to Python clients (google-cloud-storage, etc.)
          echo "GOOGLE_APPLICATION_CREDENTIALS=$(pwd)/gcp-key.json" >> $GITHUB_ENV
          echo "GOOGLE_CLOUD_PROJECT=phonic-axle-473506-u8" >> $GITHUB_ENV
          echo "Running DVC pull in same session..."
          source .venv/bin/activate
          echo "Existing DVC remotes:"
          dvc remote list || echo "No DVC remotes configured."
          echo "Configuring DVC to use service account key..."
          if dvc remote list | grep -q "^gcsremote"; then
            dvc remote modify gcsremote credentialpath $(pwd)/gcp-key.json
          elif dvc remote list | grep -q "^gcs_remote"; then
            dvc remote modify gcs_remote credentialpath $(pwd)/gcp-key.json
          else
            echo "âš ï¸ No 'gcsremote' or 'gcs_remote' found. Skipping remote credential config."
          fi
          echo "Running DVC pull:"
          dvc pull -v

      # -----------------------------
      # PRE-TRAINING VALIDATION
      # -----------------------------
      - name: Data Poisoning Check
        id: poison
        run: |
          source .venv/bin/activate
          echo "## Data Poisoning Check" > report.md
          python check_poisoning.py --data-path data/v0/transactions_2022.csv >> report.md || true
          COUNT=$(grep -oP 'Found \K[0-9]+' report.md | head -1 || true)
          echo "count=$COUNT" >> $GITHUB_OUTPUT

      - name: Abort pipeline if poisoned
        run: |
          C=${{ steps.poison.outputs.count }}
          if [ -z "$C" ]; then C=0; fi
          echo "Suspicious labels: $C"
          if [ "$C" -gt 1000 ]; then
            echo "Too many suspicious labels. Aborting."
            exit 1
          fi

      - name: Data Drift Check
        run: |
          source .venv/bin/activate
          echo "## Data Drift Check" >> report.md
          python check_drift.py >> report.md

      # -----------------------------
      # TRAINING (MLFLOW)
      # -----------------------------
      - name: Train model
        env:
          MLFLOW_TRACKING_URI: sqlite:///${{ github.workspace }}/mlflow.db
          GCS_BUCKET: ${{ env.GCS_BUCKET }}
        run: |
          source .venv/bin/activate
          python train_model.py

      # -----------------------------
      # SAVE ARTIFACTS
      # -----------------------------
      - name: Upload training artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ml-artifacts
          path: |
            artifacts/**
            mlflow.db
            mlruns/**

      # -----------------------------
      # BUILD DOCKER IMAGE
      # -----------------------------
      - name: Build & Push Docker Image
        env:
          ARTIFACT_IMAGE: ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.ARTIFACT_REPO }}/${{ env.IMAGE_NAME }}
        run: |
          docker build -t $ARTIFACT_IMAGE:latest .
          SHA=$(git rev-parse --short HEAD)
          docker tag $ARTIFACT_IMAGE:latest $ARTIFACT_IMAGE:$SHA
          docker push $ARTIFACT_IMAGE:latest
          docker push $ARTIFACT_IMAGE:$SHA
          echo "IMAGE_SHA=$ARTIFACT_IMAGE:$SHA" >> $GITHUB_ENV

      # -----------------------------
      # GKE DEPLOYMENT
      # -----------------------------
      - name: Configure kubectl
        run: |
          gcloud container clusters get-credentials $GKE_CLUSTER --zone $GKE_ZONE --project $PROJECT_ID

      - name: Deploy to GKE
        run: |
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/service.yaml
          kubectl apply -f k8s/hpa.yaml || true
          kubectl set image deployment/fraud-detection-api api-container=${IMAGE_SHA} --record
          kubectl rollout status deployment/fraud-detection-api --timeout=180s

      # -----------------------------
      # EXTERNAL IP LOOKUP
      # -----------------------------
      - name: Wait for External IP
        id: svc_ip
        run: |
          for i in {1..24}; do
            IP=$(kubectl get svc fraud-detection-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
            if [ -n "$IP" ]; then
              echo "EXTERNAL_IP=$IP" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "Waiting for service external IP..."
            sleep 5
          done
          echo "Error: External IP not assigned"
          exit 1

      # -----------------------------
      # SMOKE TEST
      # -----------------------------
      - name: Smoke Test /predict
        run: |
          IP=${{ steps.svc_ip.outputs.EXTERNAL_IP }}
          echo "Testing http://$IP:80/predict"
          curl -X POST "http://$IP/predict" \
            -H "Content-Type: application/json" \
            -d '{"transaction_id": 0}'

      # -----------------------------
      # LOCUST LOAD TEST
      # -----------------------------
      - name: Run Locust load test (2 min)
        run: |
          IP=${{ steps.svc_ip.outputs.EXTERNAL_IP }}
          source .venv/bin/activate
          locust -f locust_test.py --headless -u 50 -r 5 --run-time 2m --host http://$IP || true

      # -----------------------------
      # FINAL ARTIFACT UPLOAD
      # -----------------------------
      - name: Upload Final Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: final-artifacts
          path: |
            artifacts/**
            report.md
            mlflow.db
            mlruns/**

      # -----------------------------
      # CML REPORT (OPTIONAL)
      # -----------------------------
      - name: Setup CML
        uses: iterative/setup-cml@v2
        env:
          REPO_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Post CML Report
        if: ${{ secrets.CML_REPO_TOKEN != '' }}
        env:
          REPO_TOKEN: ${{ secrets.CML_REPO_TOKEN }}
        run: |
          echo "### Automated MLOps Report" > cml_report.md
          echo "Model + Deployment completed successfully." >> cml_report.md
          cml comment create cml_report.md
